---
layout: post
title:  "Linear Network"
date:   2021-10-06
excerpt: >-
  We are finally able to build a solid understanding of the learning flow on the simple linear network.
---

## Introduction

Here we are, having seen every $ layer $ that compose the $ model $ introduced in the "Example" of the previous 
articles. We are now ready to use the different formula we found for the learning flow in order to observe how 
they work in practice. 

## Example 

Here is the **neural structure** synthesis of the whole $ model $ we saw in the 
[weights article]({% post_url 2021-08-19-weights %}). 


Then we will use this new $ layer $ 
in order to better understand the **representations** built by the $ Linear $ $ layer $. For now, we just 
introduced these **representations** in the **forward pass** paragraph of 
[this article]({% post_url 2021-08-06-inside-the-model %}).
