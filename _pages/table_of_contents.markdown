---
layout: page
title: Table of Contents
permalink: /table_of_contents/
---

## Deep Learning meta walkthrough

### The Foundation

#### 1/ [General Concepts]({% post_url 2021-08-05-general-concepts %})

This is the first article of our walkthrough in deep learning neural networks.
First things first, we explore some general concepts of deep learning, introducing the deep learning model.

#### 2/ [Inside the Model]({% post_url 2021-08-06-inside-the-model %})

In this article, we explore the generic structure of a deep learning model.

### The Learning Process

#### 1/ [The Loss function]({% post_url 2021-08-09-loss-function %})

We complete the deep learning model with the loss function: this is the first step toward the learning process.

#### 2/ [The Backward Pass]({% post_url 2021-08-13-backward-pass %})

The backward pass is the nemesis of the forward pass: this is the second step toward the learning process.

#### 3 / [The Weights]({% post_url 2021-08-19-weights %})

The weights are the learning elements of the deep learning model: the core of the learning process.

### The Deep-Learning Algorithm

#### 1/ [The Gradient Descent Algorithm]({% post_url 2021-08-23-gradient-descent %})

We use the different parts we have seen so far to run the learning phase from scratch.

#### 2/ [Batch Learning]({% post_url 2021-08-24-batch-learning %})

A new idea to build a more robust learning: learn on multiple data input at once.

## From a Layer perspective

### The Linear Layer

#### 1/ [The Linear Layer]({% post_url 2021-09-19-linear %})

We explore the linear layer. It is the first step to be able to design deep learning models. 
We also speak about the neural structure and a better way to compute the backward pass.
