---
layout: post
title:  "The Weights"
date:   2021-08-19 20:00:00 +0200
excerpt: >-
  5/ The weights are the learning elements of the deep-learning model: final step of the learning process.
---

## Introduction

In the [previous article]({% post_url 2021-08-13-backward-pass %}), we computed the **learning flux** for each 
$ layer $ in our $ model $.  

In this article we will explore the **model's weights**, responsible for the **learning process**. 

## The model's weights

We have spoken about them for a long time now. But what are they ? 
Well, just another variable. We already saw a few of them: $ X $ the generic input variable of a $ layer $. 
$ Y^{truth} $ a variable used in the $ Loss $ function to receive the **expectations**. Here we introduce $ W $, 
the **weights**. They are the essential part for the $ model $ to be trained.

For now, none of the $ model $ functions we used in the different examples had weights. We have to add them in 
the $ layers $ of our $ model $. But it is not necessary to use them in every $ layer $. 

So for each $ layer $ $ L^k $ that declares **weights**, we will have two dependencies: $ X^k $ and $ W^k $.
And for each $ layer $ $ L^i $ that does not declare **weights**, we stay with one dependency: $ X^i $.

## The learning process 

What about the learning part ? 
In the paragraph "Learning, inferring" of the [first article]({% post_url 2021-08-05-general-concepts %}), we 
wanted to "teach" the $ model $ so that it learns to produce good results on the **data**. We even mentioned the 
learning part to be linked with the **weights**.

In fact $ W $ is a special variable: sometimes it will be a variable and sometimes not.
That is the main reason of the existence of the **learning phase** we introduced in the 
[first article]({% post_url 2021-08-05-general-concepts %}). 

During the **learning phase**, $ W $ will be a variable and we will modify it so that the modifications help the 
$ model $ to produce better results. 

During the **inferring phase**, $ W $ won't be a variable any more. 
It will stay at the last value it had during the **learning phase**. 

We hope that during the **learning phase** the $ model $'s understanding of the **data** is getting better and better, 
 so that this last value is the best that was learnt during the **training phase**. 
 
There is one last subtlety about $ W $. It is not linked to the **information flux** so is $ X $. 
For example if we consider $ L2 $ and $ L3 $: $ X^3 = L2(X^2) $ because of the **forward pass**. It means that 
during the **forward pass**, the values of these variables are passing from $ L2 $ to $ L3 $. But if $ L2 $ has $ W^2 $, 
$ W^2 $ value won't change at all during the **forward pass**. It will only be modified when the developer decides.
In that way, $ W $ has a meta role.

![Warning](/_assets/images/maths/warning.png) mathematically shy people should jump to the [next title](#update-the-weights)

## The backward pass for weights
 
In the article on the [Loss function]({% post_url 2021-08-09-loss-function %}), we saw a way to link 
a variable to the impacts it has on the $ model $. 

Now we will do the same with the **weights**. As a variable, they are also responsible for the errors that 
are highlighted by the $ Loss $ function. The link is: 

$$
\begin{align}
    derivative \text{ }Loss \text{ according to } W &= \frac{\partial}{\partial W}(Loss(W, Y^{truth})) \\ 
                                                    &= \frac{\partial Loss}{\partial W}
\end{align}
$$

Let us keep in mind this formula for the $ derivative $ function of $ Loss $ according to $ W $: 

$$
\boxed{\frac{\partial Loss}{\partial W}} 
$$

As we mentioned in the paragraph "The derivatives of the [Loss function]({% post_url 2021-08-09-loss-function %})", 
this $ derivative $ is a function and it produces the same kind of results 
as $ Loss(X, W, Y^{truth}) $. Note that we added a new $ W $ dependency in the $ Loss $ function.

But due to the subtlety we talked about in the [previous paragraph](#the-learning-process), we will only consider 
the variable in order to obtain the explicit form of the $ derivative $ function. But once we get it, we do not 
specially care about evaluating our $ derivative $ function on $ x $, $ w $ and $ y^{truth} $ but just on 
$ x $ and $ y^{truth} $, because the current value for $ w $ never changes during the **forward pass**. 
So we will evaluate:

$$
\boxed{\frac{\partial Loss}{\partial W}(x, y^{truth})}
$$

We could paraphrase the formula as: we want to know to what extent the variable $ W $ has caused an error in the 
$ model $ when the $ Loss $ function was evaluated on $ x $ and $ y^{truth} $.

![Safe](/_assets/images/maths/safe.png) 

## Update the weights

We said that the value for the **weights** never changed during the **forward pass** but we also said that we had 
to modify it in order to learn something. 

These modifications will indeed happen during the **backward pass**. 
If the **forward pass** is all about producing results, we could see the **backward pass** as a sort a freeze time in 
which an extra player (the developer) happens to change the rules and boost the model for it to perform better 
during the next **forward pass**. 

The formula to update the **weights** is: 

$$
\boxed{\hat{W} = W - \alpha * \frac{\partial Loss}{\partial W}}
$$

We use $ \hat{W} $ to formalize the modification of $ W $. 
We will talk about the intuition for the formula in a later article.

## The optimizer

The main part of the formula is the direction of the update, given by: $ \frac{\partial Loss}{\partial W} $.
Then there is a coefficient that gives the speed at which we go in this direction: $ \alpha $.
$ \alpha $ is called the **learning rate**.

There exist other formula to update the **weights**, but the most prominent parts are of course the current value 
of the **weight**: $ W $ and $ \frac{\partial Loss}{\partial W} $.

The **optimizer** is the typical name for the component in charge of updating the **weights** in a deep-learning 
framework. 
 
## Example

We will use the same example as in the previous articles. But we will add some **weights** to our $ model $.

### <span style="text-decoration:underline"> Data </span>

Same **data** as in the [first article]({% post_url 2021-08-05-general-concepts %}).

| data input | data output (expectation) |
| ---------------- | ----- |
| (100 broccoli, 2000 Tagada strawberries, 100 workout hours) | (bad shape)  |
| (200 broccoli,  0 Tagada strawberries, 0 workout hours)     | (good shape) |
| (0 broccoli, 2000 Tagada strawberries, 3 000 workout hours) | (good shape) |

### <span style="text-decoration:underline"> Model </span> 

We assume we have "nearly" the same $ model $ containing only 3 $ layers $ and a $ Loss $ function. 
But we modify $ L2 $ to add some **weights**. 
Previously we had: 

$$ 
L2(X^2) = \frac{1}{200} X^2_1 - \frac{3 000}{11 600 000}  X^2_2 + 
        \frac{1}{5 800} X^2_3 \text{ with } X^2 = (X^2_1, X^2_2, X^2_3)
$$

Now we change it to:

$$ 
\begin{align}
    L2(X^2, W^2) &= W^2 . X^2 & \text{ with } X^2 = (X^2_1, X^2_2, X^2_3) \\
                 &            & \text{ and } W^2 = (W^2_1, W^2_2, W^2_3) \\
                 &= W^2_1 . X^2_1 + W^2_2 . X^2_2 + W^2_3 . X^2_3 & 
\end{align}
$$

Here are all the $ layers $:

$$
\begin{align}
    L1(X^1)  &= X^1 & \text{ with } X^1 = (X^1_1, X^1_2, X^1_3) \\
    L2(X^2, W^2) &= W^2 . X^2          & \text{ with } X^2 = (X^2_1, X^2_2, X^2_3) \\
                 &                     & \text{ and } W^2 = (W^2_1, W^2_2, W^2_3) \\
                 &= W^2_1 . X^2_1 + W^2_2 . X^2_2 + W^2_3 . X^2_3 \\
    L3(X^3)  &= X^3 \text{ if } X^3 \geq 0 \text{ else } 0 \\ \\
    model(X) &= L3(L2(L1(X))) & \text{ with } X = (X_1, X_2, X_3) \\ 
    Loss(X^4, Y^{truth})  &= \frac{1}{2} (X^4 - Y^{truth})^2 
\end{align}
$$

We have indeed introduced **weights** in $ L2 $. But as any variable, we must pick some value in order to 
compute something. So let us say that the current values for $ W^2 $ are the same values we already used in the 
previous $ L2 $ function: 

$$ 
w^2 = (\frac{1}{200}, -\frac{3 000}{11 600 000}, \frac{1}{5 800})
$$

When we evaluate $ L2 $ on $ o1 $ output from $ L1 $ we have:

$$ 
L2(o1, w^2) = w^2 * o1 = \frac{1}{200} * o^1_1 - \frac{3 000}{11 600 000} * o^1_2 + \frac{1}{5 800} * o^1_3
$$

which is exactly what we had when running the forward pass in the previous articles.

### <span style="text-decoration:underline"> Run the forward pass </span>

Same as in the [Loss function article]({% post_url 2021-08-09-loss-function %}):

![Warning](/_assets/images/maths/warning.png) mathematically shy people should skip

### <span style="text-decoration:underline"> Run the backward pass for the learning flux </span>

We can use the results we computed in the [Loss function article]({% post_url 2021-08-09-loss-function %}) and 
in the [previous article]({% post_url 2021-08-13-backward-pass %}).

![Layers](/_assets/images/backward/Layer-3.png)

$$ 
\boxed{\delta 4 = o3 - y^{truth}} 
$$

$$ 
\boxed{\delta 3 = \delta 4 \text{ if } o2 \geq 0 \text{ else } 0}
$$

$$ 
\delta 2 = \delta 3 * (\frac{1}{200}, -\frac{3 000}{11 600 000}, \frac{1}{5 800})
$$

$$ 
\boxed{\delta 1 = \delta 2}
$$

But we keep in mind that: 

$$ 
\boxed{\delta 2 = \delta 3 . w2 \text{ with } w^2 = (\frac{1}{200}, -\frac{3 000}{11 600 000}, \frac{1}{5 800})}
$$

### <span style="text-decoration:underline"> Run the backward pass for the weights </span>

We are now going to use the **learning flux** to compute the $ derivative $ functions of $ Loss $ according to 
the **weights**. 

As in the [Loss function article]({% post_url 2021-08-09-loss-function %}), we are looking for every $ layer $ 
that needs to update some **weights**. There is only $ L2 $ in this case.

So we have to compute:

$$ 
\boxed{\frac{\partial Loss}{\partial W^2}} 
$$

As in the [previous article]({% post_url 2021-08-13-backward-pass %}), we are looking for a link 
between $ W^2 $ and $ Loss $. Once again the idea is to use the **backward pass** to link what we have already 
computed and what is close to $ L2 $: 

$$ 
\begin{align}
    L2(X^2, W^2) &= W^2 . X^2 & \text{ with } X^2 = (X^2_1, X^2_2, X^2_3) \\
                 &            & \text{ and } W^2 = (W^2_1, W^2_2, W^2_3) \\
                 &= W^2_1 . X^2_1 + W^2_2 . X^2_2 + W^2_3 . X^2_3 & 
\end{align}
$$

As previously, we remark that $ W^2 = (W^2_1, W^2_2, W^2_3) $. 
Thus, we have to compute the $ derivative $ functions of $ Loss $ according to each of them:

$$
\frac{\partial Loss}{\partial W^2_1} \text{, } \frac{\partial Loss}{\partial W^2_2} \text{ and } 
\frac{\partial Loss}{\partial W^2_3}
$$

We are able to use the **chain rule** with $ z = Loss $ and $ y = L2 $, for $ W^2_1 $ the formula becomes: 

$$ 
\boxed{\frac{\partial Loss}{\partial W^2_1} = \frac{\partial Loss}{\partial L2} . \frac{\partial L2}{\partial W^2_1}}
$$

Thanks to the **forward pass** we know that $ X^3 = L2(X^2) $, so we have: 

$$
\frac{\partial Loss}{\partial L2} = \frac{\partial Loss}{\partial X^3} \text{ computed in the previous article !}
$$

and: 

$$
\begin{align}
    \frac{\partial L2}{\partial W^2_1} &= \frac{\partial (W^2_1 . X^2_1 + W^2_2 . X^2_2 + 
        W^2_3 . X^2_3)}{\partial W^2_1} \text{ with the definition of } L2(X^2, W^2) \\
                                       &= X^2_1
\end{align}
$$

Assembling those results: 

$$
\begin{align}
    \frac{\partial Loss}{\partial W^2_1} &= \frac{\partial Loss}{\partial L2} . \frac{\partial L2}{\partial W^2_1} \\
                                         &= (\frac{\partial Loss}{\partial X^3}) * (X^2_1) 
\end{align}
$$

And because $ \frac{\partial Loss}{\partial W^2_1} $ is a function depending on $ X^2 $ 
we can apply it on the values that produced the errors highlighted by $ Loss $: 

$$
\begin{align}
    \frac{\partial Loss}{\partial W^2_1}(o1) &= \frac{\partial Loss}{\partial X^3}(o2) *  o1_1 \\ 
                                             &= \delta 3 * o1_1
\end{align}
$$

We have found: 

$$ 
\frac{\partial Loss}{\partial W^2_1}(o1) = \delta 3 * o1_1
$$

We do the same to compute: 

$$ 
\frac{\partial Loss}{\partial W^2_2}(o1) = \delta 3 * o1_2
$$

and 

$$ 
\frac{\partial Loss}{\partial W^2_3}(o1) = \delta 3 * o1_3
$$

These 3 formulas can be summarized as: 

$$ 
\boxed{\frac{\partial Loss}{\partial W^2}(o1) = \delta 3 * o1}
$$

![Safe](/_assets/images/maths/safe.png) 

### <span style="text-decoration:underline"> Update the weights </span>

We are finally able to update the weights in our $ model $ and it is by far the easiest part !

In order to proceed, we will use the formula given in [this paragraph](#update-the-weights).
The new value $ \hat{w^2} $ for our $ w^2 $ **weights** will be:

$$
\begin{align}
    \hat{w^2} &= w^2 - \alpha * \frac{\partial Loss}{\partial W^2}(o1)
              &= w^2 - \alpha * \delta 3 * o1
\end{align}
$$

And in the paragraph "Run the backward pass for the learning flux" we computed as well:

$$ 
\boxed{\delta 4 = o3 - y^{truth}} 
$$

$$ 
\boxed{\delta 3 = \delta 4 \text{ if } o2 \geq 0 \text{ else } 0}
$$

So now we can use some numeric values. Let us take $ \alpha = 1.0 $.
Here are the values we computed during the **forward pass**: 

| $ x $              | $ o1 = L1(x) $   | $ o2 = L2(o1) $ | $ o3 = L3(o2) $ |
| :----------------: | :--------------: | :-------------: | :-------------: |
| (100, 2000, 100)   | (100, 2000, 100) | (0)             | (0)             |
| (200,  0, 0)       | (200,  0, 0)     | (1)             | (1)             |
| (0, 2000, 3 000)   | (0, 2000, 3 000) | (0)             | (0)             |

| $ o3 = model(x) $ | $ y^{truth} $ = expected result | $ loss = Loss(o3, y^{truth}) $ | correct ? |
| :----: | :-----: | :-----: | :---: |
| (0) | (0) | (<span style="color:green">0</span>) | ![wrong](/_assets/images/general/right.png) |
| (1) | (1) | (<span style="color:green">0</span>) | ![wrong](/_assets/images/general/right.png) |
| (0) | (1) | (<span style="color:red">0.5</span>) | ![right](/_assets/images/general/wrong.png) |

#### Run the model on the 1st data input

Let us say we are running our $ model $ on the first **data input**: $ x = (100, 2000, 100) $, we have 

$$
\begin{align}
    o3 &= model(x) \\ 
       &= model((100, 2000, 100)) \\
       &= (0)
\end{align}
$$

Thus we compute: 

$$ 
\begin{align}
    \delta 4 &= o3 - y^{truth} \\
             &= (0) - (0) \\
             &= (0)
\end{align}
$$

then: 

$$ 
\begin{align}
    \delta 3 &= \delta 4 \text{ if } o2 \geq 0 \text{ else } 0 \\
             &= (0) \text{ if } (0) \geq 0 \text{ else } 0 \\
             &= (0)
\end{align}
$$

and finally: 

$$
\begin{align}
    \hat{w^2} &= w^2 - \alpha * \delta 3 * o1 \\
              &= (\frac{1}{200}, -\frac{3 000}{11 600 000}, \frac{1}{5 800}) - 1 * (0) * (100, 2000, 100) \\
              &= (\frac{1}{200}, -\frac{3 000}{11 600 000}, \frac{1}{5 800})
\end{align}
$$

So it appears the new value for $ w^2 $ is still the same !
This is no wonder as for this first **data input**: $ loss = 0 $.
This $ loss $ value is typical for a $ model $ that has already produced the right result and has nothing to learn.

#### Run the model on the 2nd data input

Now let us run our $ model $ on the second **data input**: $ x = (200,  0, 0) $, we have 

$$
\begin{align}
    o3 &= model(x) \\ 
       &= model((200,  0, 0)) \\
       &= (1)
\end{align}
$$

Thus we compute: 

$$ 
\begin{align}
    \delta 4 &= o3 - y^{truth} \\
             &= (1) - (1) \\
             &= (0)
\end{align}
$$

then: 

$$ 
\begin{align}
    \delta 3 &= \delta 4 \text{ if } o2 \geq 0 \text{ else } 0 \\
             &= (0) \text{ if } (1) \geq 0 \text{ else } 0 \\
             &= (0)
\end{align}
$$

and finally: 

$$
\begin{align}
    \hat{w^2} &= w^2 - \alpha * \delta 3 * o1 \\
              &= (\frac{1}{200}, -\frac{3 000}{11 600 000}, \frac{1}{5 800}) - 1 * (0) * (200,  0, 0) \\
              &= (\frac{1}{200}, -\frac{3 000}{11 600 000}, \frac{1}{5 800})
\end{align}
$$

Once more, the new value for $ w^2 $ has not changed.
The same remark as before applies: $ loss = 0 $ means the $ model $ already produced the right result for this 
second **data input** and has nothing to learn.

#### Run the model on the 3rd data input

Now let us run our $ model $ on the third **data input**: $ x = (0, 2000, 3 000) $, we have 

$$
\begin{align}
    o3 &= model(x) \\ 
       &= model((0, 2000, 3 000)) \\
       &= (0)
\end{align}
$$

Thus we compute: 

$$ 
\begin{align}
    \delta 4 &= o3 - y^{truth} \\
             &= (0) - (1) \\
             &= (-1)
\end{align}
$$

then: 

$$ 
\begin{align}
    \delta 3 &= \delta 4 \text{ if } o2 \geq 0 \text{ else } 0 \\
             &= (-1) \text{ if } (0) \geq 0 \text{ else } 0 \\
             &= (-1)
\end{align}
$$

and finally: 

$$
\begin{align}
    \hat{w^2} &= w^2 - \alpha * \delta 3 * o1 \\
              &= (\frac{1}{200}, -\frac{3 000}{11 600 000}, \frac{1}{5 800}) - 1 * (-1) * (0, 2000, 3 000) \\
              &= (\frac{1}{200}, 2000 - \frac{3 000}{11 600 000}, 3 000 + \frac{1}{5 800})
\end{align}
$$

Now we have a the new value for $ w^2 $ !
We observe that $ loss = 0.5 > 0 $: there was something to learn on this last **data input**.
Hence the modification of the **weights** to compensate the failure.

## Conclusion

In this article we finally introduced **weights** in our $ model $. 
We also used the **learning flux** in order to compute the $ derivative $ functions of $ Loss $ according to these 
**weights**. And we used these $ derivative $ functions to compute new values for the **weights** themselves. 

Is the **learning process** over now ?
Technically yes, but we have to consider the way we updated the **weights**. 
We did use the formula, but we were 
a little heavy on the **learning rate**. 

In the next article, we will see why.
